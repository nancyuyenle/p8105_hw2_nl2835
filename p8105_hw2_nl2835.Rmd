---
title: "p8105_hw2_nl2835"
author: "Nancy Le"
date: 09-28-2023
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

```{r load_libraries}
library(tidyverse)
library(readxl)

```

### Problem 1: 

We import and clean the FiveThirtyEight `pols_month_df` data, which gives the number of national politicians who are democratic or republican. Some values of `prez_gop` are `2` - we code them as `gop` in the new `prez` variable. 

```{r clean_538_pols}

month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols_month_df = 
  read_csv(file = "./fivethirtyeight_datasets/pols-month.csv") |> 
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |> 
  mutate(prez = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 

```



We import and clean the FiveThirtyEight `SNP_df` data, which gives the monthly closing values of the S&P 500 by year. 

```{r clean_528_snp}
SNP_df = 
  read_csv(file = "./fivethirtyeight_datasets/snp.csv") |> 
  separate(date, into = c("month", "day", "year"), sep = "/", convert = TRUE) |> 
  mutate(month = month.name[month]) |> 
  arrange(year, month) |> 
  select(year, month, close)
```


We clean the `unemployment_df` data to merge with `pols_month_df` and `SNP_df` datasets.


```{r clean_538_unemp}
unemployment_df = 
  read_csv(file = "./fivethirtyeight_datasets/unemployment.csv") |> 
  rename(year = Year) |> 
  pivot_longer(
    Jan:Dec,
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _,  y = month_df) |> 
  select(year, month, unemployment)
```

Merging 3 datasets

```{r merge 538}
fivethirtyeight_data = 
  left_join(pols_month_df, SNP_df) |> 
  left_join(x = _, y = unemployment_df)


str(fivethirtyeight_data)
```



###Problem 2:

```{r}
trashwheel_df = 
  readxl::read_excel("./mr_trashwheel/trashwheel_collection.xlsx", 1,
        range = "A2:N549") |> 
  janitor::clean_names() |> 
  mutate(
    sheet = "mister trashwheel", homes_powered_v2 = (weight_tons * 500) / 
      30) |> 
  select(dumpster, year, month, everything(), -homes_powered)
```



```{r clean prof trashwheel names}
proftrashwheel_df = 
  readxl::read_excel("./mr_trashwheel/trashwheel_collection.xlsx", 2,
        range = "A2:M96") |> 
  janitor::clean_names()
  

proftrashwheel_df = proftrashwheel_df |> 
  mutate(
    homes_powered_v2 = (weight_tons * 500) / 30) |> 
  mutate(sheet = "professor trashwheel") |> 
  select(dumpster, year, month, everything(), -homes_powered)


```


Imported, cleaned, and organized Professor Trash Wheel data.

```{r}
gwynnda_df = 
  readxl::read_excel("./mr_trashwheel/trashwheel_collection.xlsx", 4,
        range = "A2:K108") |> 
  mutate(sheet = "gwynnda") |> 
  janitor::clean_names()

gwynnda_df = gwynnda_df |> 
  mutate(homes_powered_v2 = (weight_tons * 500) / 30) |> 
  select(dumpster, year, month, everything(), -homes_powered)
```

Imported, cleaned, and organized Gwynnda data.

```{r}
proftrashwheel_df <- proftrashwheel_df |>   
    mutate(year = as.numeric(year))


trashwheel_df <- trashwheel_df |>   
    mutate(year = as.numeric(year))

```


```{r merge_trash}
trashwheel_collection = 
  left_join(gwynnda_df, proftrashwheel_df) |>
  left_join(x = _, y = trashwheel_df)

str(trashwheel_collection)
```

```{r}
trashwheel_collection_data =  
     full_join(gwynnda_df, proftrashwheel_df, by = c("dumpster",
              "month", "year", "date", "weight_tons", "volume_cubic_yards", 
              "plastic_bottles", "polystyrene", "cigarette_butts",
              "homes_powered_v2", "sheet"))

```



```{r}
trashwheel_collection_data_total = 
     full_join(trashwheel_collection_data, trashwheel_df, by = c("dumpster",
              "month", "year", "date", "weight_tons", "volume_cubic_yards", 
              "plastic_bottles", "polystyrene", "cigarette_butts", 
              "sheet", "glass_bottles", "grocery_bags", "homes_powered_v2",
              "chip_bags"))

```


This combined data set has ```r nrow(trashwheel_collection_data_total)``` and
```r ncol(trashwheel_collection_data_total)``` columns. The variables are: dumpster #, month, year, date, weight in tons, volume in cubic yards, plastic bottles, polystyrene, cigarette butts, plastic bags, which sheet the data is from, homes powered, glass bottles, grocery bags, chip bags, and sports balls. 

```{r}
ptwtons = trashwheel_collection_data_total |> 
  filter(sheet=="professor trashwheel") |> 
  pull(weight_tons) |> 
  sum() 

```


The total weight of trash collected by Professor Trash Wheel was ```r ptwtons``` tons.


```{r}
totalcigsgwyn = trashwheel_collection_data_total |> 
  filter(sheet=="gwynnda", year=="2021", month=="July") |> 
  pull(cigarette_butts) |> 
  sum() 
```


The total number of cigarette butts collected by Gwynnda in July of 2021 was ```r totalcigsgwyn```.
 



Problem #3

```{r import MCI baseline data}
baseline_df = 
  read_csv("./data_mci/mci_baseline.csv", skip = 1) |> 
  janitor::clean_names() 
```


```{r}
baseline_df = baseline_df |> 
 mutate(
   sex = ifelse(sex == 1, "male", "female"),
   apoe4 = (apoe4 == "1"),
   )
```

```{r}
new_baseline <- baseline_df |> 
  filter(age_at_onset != ".")
```

Important steps in the import process were to skip the first row of the csv file so that there were not two rows of variable names. Names were cleaned to be usable in R, and sex and APOE4 carrier status were changed to a male/female character variable and a logical variable, respectively.

There were ```r nrow(baseline_df)``` participants recruited, and of these, ```r nrow(new_baseline)``` developed MCI. 

The average baseline age for participants in the study is ```r mean(pull(new_baseline, current_age))```. The proportion of women in the study who are APOE4 carriers are ```r mean(pull(new_baseline, apoe4))```.


```{r import MCI amyloid data}
library(tidyverse)
amyloid_df = 
  read_csv("./data_mci/mci_amyloid.csv", skip = 1) |> 
  janitor::clean_names() 
```

```{r}
amyloid_df = amyloid_df |> 
  pivot_longer(
    baseline:time_8,
    names_to = "observation_time",
    values_to = "years_elapsed"
  ) |> 
  filter(years_elapsed != ".") |> 
  rename(id = study_id)
```

Steps of importing the `amyloid_df` data were to read the csv, clean the column names, pivot the data from wide to long, filter for non-missing values, and rename `study_id` to `id` so it can be merged with `new_baseline`.

The `new_baseline` data has fewer subjects than in the `amyloid_df` data, as we removed subjects who did not develop MCI from study inclusion. The `amyloid_df` data keeps track of time (in years) elapsed between each subject's observations (independent of study inclusion/exclusion). 


You are currently on the last paragraph of the HW assignment; still need to go back and revisit inline code description for Problem 1; make sure have all parts of the HW done

```{r}
amy_base = 
  inner_join(new_baseline, amyloid_df, by = "id")
```

